{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c11936fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import pathlib as Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "035e3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mof_dataset = pd.read_csv(r\"C:\\Users\\dalja\\OneDrive\\Desktop\\APS360 Project\\MOF_CORE_final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "453299fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MOFid', 'metal', 'linker', 'logKH_CO2', 'pure_uptake_CO2_298.00_15000',\n",
       "       'pure_uptake_methane_298.00_6500000', 'LCD', 'PLD', 'LFPD', 'cm3_g',\n",
       "       'ASA_m2_cm3', 'ASA_m2_g', 'NASA_m2_cm3', 'NASA_m2_g', 'AV_VF',\n",
       "       'AV_cm3_g', 'NAV_cm3_g', 'All_Metals', 'Has_OMS', 'Open_Metal_Sites'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mof_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90a8dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_info = mof_dataset[['LCD', 'PLD', 'LFPD', 'cm3_g',\n",
    "       'ASA_m2_cm3', 'ASA_m2_g', 'NASA_m2_cm3', 'NASA_m2_g', 'AV_VF',\n",
    "       'AV_cm3_g', 'NAV_cm3_g']]\n",
    "\n",
    "precursors_info = mof_dataset[['MOFid', 'metal', 'linker', 'Has_OMS', 'Open_Metal_Sites']]\n",
    "\n",
    "target_info = mof_dataset[['logKH_CO2', 'pure_uptake_CO2_298.00_15000', 'pure_uptake_methane_298.00_6500000']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77884f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_scaler.pkl']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Standardize geometry features\n",
    "geometry_scaler = StandardScaler()\n",
    "geometry_info_norm = pd.DataFrame(\n",
    "    geometry_scaler.fit_transform(geometry_info),\n",
    "    columns=geometry_info.columns,\n",
    "    index=geometry_info.index\n",
    ")\n",
    "\n",
    "# Standardize targets\n",
    "target_scaler = StandardScaler()\n",
    "target_info_norm = pd.DataFrame(\n",
    "    target_scaler.fit_transform(target_info),\n",
    "    columns=target_info.columns,\n",
    "    index=target_info.index\n",
    ")\n",
    "\n",
    "# Save scalers\n",
    "import joblib\n",
    "joblib.dump(geometry_scaler, 'geometry_scaler.pkl')\n",
    "joblib.dump(target_scaler, 'target_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce26f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCD           -0.930531\n",
      "PLD           -1.071692\n",
      "LFPD          -1.083744\n",
      "cm3_g         -2.542419\n",
      "ASA_m2_cm3    -1.413214\n",
      "ASA_m2_g      -1.001030\n",
      "NASA_m2_cm3   -0.472329\n",
      "NASA_m2_g     -0.431001\n",
      "AV_VF         -2.643680\n",
      "AV_cm3_g      -0.961112\n",
      "NAV_cm3_g     -0.025221\n",
      "dtype: float64\n",
      "LCD            13.329026\n",
      "PLD             9.864606\n",
      "LFPD           13.678638\n",
      "cm3_g           6.537135\n",
      "ASA_m2_cm3      2.608635\n",
      "ASA_m2_g        5.548906\n",
      "NASA_m2_cm3     5.653545\n",
      "NASA_m2_g       9.040795\n",
      "AV_VF           3.609937\n",
      "AV_cm3_g       29.896164\n",
      "NAV_cm3_g      57.070888\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(geometry_info_norm.min())\n",
    "print(geometry_info_norm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c482e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logKH_CO2                            -5.013828\n",
      "pure_uptake_CO2_298.00_15000         -1.299537\n",
      "pure_uptake_methane_298.00_6500000   -1.258191\n",
      "dtype: float64\n",
      "logKH_CO2                              2.949122\n",
      "pure_uptake_CO2_298.00_15000           4.699299\n",
      "pure_uptake_methane_298.00_6500000    11.045829\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(target_info_norm.min())\n",
    "print(target_info_norm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2f26700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Na][Y][W][Cs]\n",
      "[W][Na][K][Rb][Y]\n",
      "[Co][K][W][Cu]\n",
      "[Co][K][W][Cr]\n",
      "[Na][Mo][Al][Eu]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in precursors_info['metal']:\n",
    "    if len(i) > 12:\n",
    "        print(i)\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b0bd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metal_string(metal_str):\n",
    "\n",
    "    metals = re.findall(r'\\[([^\\]]+)\\]', metal_str)\n",
    "    \n",
    "    return metals\n",
    "\n",
    "def build_metal_vocabulary(df, metal_column='metal'):\n",
    "\n",
    "    all_metals = set()\n",
    "    max_metals = 0\n",
    "    \n",
    "    for metal_str in df[metal_column]:\n",
    "        metals = parse_metal_string(str(metal_str))\n",
    "        all_metals.update(metals)\n",
    "        max_metals = max(max_metals, len(metals))\n",
    "    \n",
    "    # Create vocabulary with padding token\n",
    "    unique_metals = sorted(all_metals)\n",
    "    metal_to_idx = {'<NONE>': 0}  # Padding token\n",
    "    metal_to_idx.update({metal: i+1 for i, metal in enumerate(unique_metals)})\n",
    "    \n",
    "    print(f\"Found {len(unique_metals)} unique metals\")\n",
    "    print(f\"Vocabulary size: {len(metal_to_idx)} (including padding)\")\n",
    "    print(f\"Maximum metals per MOF: {max_metals}\")\n",
    "    \n",
    "    return metal_to_idx, max_metals\n",
    "\n",
    "def encode_metals(df, metal_to_idx, max_length, metal_column='metal', oms_column='Open_Metal_Sites'):\n",
    "    \"\"\"\n",
    "    Convert metal strings to integer sequences with OMS flags.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with metal and OMS columns\n",
    "        metal_to_idx: Metal vocabulary dictionary\n",
    "        max_length: Sequence length (pad/truncate to this)\n",
    "        metal_column: Name of metal column\n",
    "        oms_column: Name of Open Metal Sites column\n",
    "    \n",
    "    Returns:\n",
    "        metal_ids: Array of shape (n_mofs, max_length)\n",
    "        metal_oms_flags: Array of shape (n_mofs, max_length)\n",
    "    \"\"\"\n",
    "    n_mofs = len(df)\n",
    "    metal_ids = np.zeros((n_mofs, max_length), dtype=np.int32)\n",
    "    metal_oms_flags = np.zeros((n_mofs, max_length), dtype=np.float32)\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        # Parse metals\n",
    "        metals = parse_metal_string(str(row[metal_column]))\n",
    "        \n",
    "        # Convert to IDs (truncate if too long)\n",
    "        for j, metal in enumerate(metals[:max_length]):\n",
    "            metal_ids[i, j] = metal_to_idx.get(metal, 0)\n",
    "        \n",
    "        # Parse OMS\n",
    "        oms_str = str(row[oms_column])\n",
    "        if oms_str and oms_str != 'nan' and oms_str.strip():\n",
    "            oms_metals = [m.strip() for m in oms_str.replace('[', '').replace(']', '').split(',')]\n",
    "            \n",
    "            # Set OMS flags\n",
    "            for j, metal in enumerate(metals[:max_length]):\n",
    "                if metal in oms_metals:\n",
    "                    metal_oms_flags[i, j] = 1.0\n",
    "    \n",
    "    return metal_ids, metal_oms_flags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a34aa76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 unique metals\n",
      "Vocabulary size: 55 (including padding)\n",
      "Maximum metals per MOF: 5\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "# Step 1: Build vocabulary\n",
    "metal_vocab, max_metals = build_metal_vocabulary(precursors_info, metal_column='metal')\n",
    "\n",
    "# Step 2: Encode all metals\n",
    "metal_ids, metal_oms_flags = encode_metals(\n",
    "    precursors_info, \n",
    "    metal_vocab, \n",
    "    max_length=max_metals,  # Or set fixed length like 5\n",
    "    metal_column='metal',\n",
    "    oms_column='Open_Metal_Sites'\n",
    ")\n",
    "\n",
    "# Step 3: Add to dataset\n",
    "precursors_info_encoded = precursors_info.copy()  # To avoid SettingWithCopyWarning\n",
    "precursors_info_encoded['metal_ids'] = list(metal_ids)\n",
    "precursors_info_encoded['metal_oms_flags'] = list(metal_oms_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d87e428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<NONE>': 0, 'Ag': 1, 'Al': 2, 'Au': 3, 'Ba': 4, 'Be': 5, 'Bi': 6, 'Ca': 7, 'Cd': 8, 'Ce': 9, 'Co': 10, 'Cr': 11, 'Cs': 12, 'Cu': 13, 'Dy': 14, 'Er': 15, 'Eu': 16, 'Fe': 17, 'Ga': 18, 'Gd': 19, 'Hf': 20, 'Ho': 21, 'In': 22, 'Ir': 23, 'K': 24, 'La': 25, 'Li': 26, 'Lu': 27, 'Mg': 28, 'Mn': 29, 'Mo': 30, 'Na': 31, 'Nb': 32, 'Nd': 33, 'Ni': 34, 'Pb': 35, 'Pd': 36, 'Pr': 37, 'Pt': 38, 'Rb': 39, 'Re': 40, 'Rh': 41, 'Ru': 42, 'Sm': 43, 'Sn': 44, 'Sr': 45, 'Tb': 46, 'Th': 47, 'Tm': 48, 'U': 49, 'V': 50, 'W': 51, 'Y': 52, 'Yb': 53, 'Zn': 54}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['metal_vocabulary.pkl']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metal_vocab)\n",
    "joblib.dump(metal_vocab, 'metal_vocabulary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "13ed5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [29, 0, 0, 0, 0]\n",
      "1       [10, 0, 0, 0, 0]\n",
      "2       [13, 0, 0, 0, 0]\n",
      "3       [25, 0, 0, 0, 0]\n",
      "4        [9, 0, 0, 0, 0]\n",
      "              ...       \n",
      "3328     [8, 0, 0, 0, 0]\n",
      "3329    [34, 8, 0, 0, 0]\n",
      "3330    [34, 8, 0, 0, 0]\n",
      "3331    [54, 0, 0, 0, 0]\n",
      "3332    [49, 0, 0, 0, 0]\n",
      "Name: metal_ids, Length: 3333, dtype: object\n",
      "0       [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "1       [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2       [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3       [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "4       [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "                  ...            \n",
      "3328    [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3329    [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3330    [1.0, 1.0, 0.0, 0.0, 0.0]\n",
      "3331    [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3332    [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: metal_oms_flags, Length: 3333, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(precursors_info_encoded['metal_ids'])\n",
    "print(precursors_info_encoded['metal_oms_flags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4d56d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_linker(df, linker_column='linker'):\n",
    "    linkers = df[linker_column].tolist()\n",
    "\n",
    "    # Build vocabulary\n",
    "    linker_vocab = sf.get_alphabet_from_selfies(linkers)\n",
    "    linker_vocab.add('[nop]')  # Padding token\n",
    "    linker_vocab = list(sorted(linker_vocab))\n",
    "\n",
    "    # Determine padding length\n",
    "    pad_to_len = max(sf.len_selfies(s) for s in linkers)\n",
    "    \n",
    "    # Create symbol to index mapping\n",
    "    symbol_to_idx = {s: i for i, s in enumerate(linker_vocab)}\n",
    "\n",
    "    print(f\"Linker vocabulary size: {len(linker_vocab)}\")\n",
    "    print(f\"Padding length: {pad_to_len}\")\n",
    "\n",
    "    # Encode each linker\n",
    "    onehot_encodings = []\n",
    "    labels = []\n",
    "\n",
    "    for linker in linkers:\n",
    "        label, onehot_encoding = sf.selfies_to_encoding(\n",
    "            selfies=linker,\n",
    "            vocab_stoi=symbol_to_idx,\n",
    "            pad_to_len=pad_to_len,\n",
    "            enc_type=\"both\"\n",
    "        )\n",
    "        onehot_encodings.append(onehot_encoding)\n",
    "        labels.append(label)\n",
    "\n",
    "    onehot_encodings = np.array(onehot_encodings)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return labels, onehot_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b5d49762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linker vocabulary size: 86\n",
      "Padding length: 198\n"
     ]
    }
   ],
   "source": [
    "labels, linker_ids = encode_linker(precursors_info_encoded, linker_column='linker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1b2467bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 36 19 46 19 46 27 58 23 46 36 19 46 19 46 27 58 23 46 36 19 46 19 46\n",
      " 27 58 23 66  3 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85\n",
      " 85 85 85 85 85 85]\n",
      "(198,)\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])\n",
    "print(labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c2d7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "(198, 86)\n"
     ]
    }
   ],
   "source": [
    "print(linker_ids[0])\n",
    "print(linker_ids[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precursors_info_encoded = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
